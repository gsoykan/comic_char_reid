# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: triplet_vae.yaml
  - override /model: triplet_id_net_fine_tuned.yaml
  - override /callbacks: wandb.yaml # default.yaml - wandb.yaml - wandb_no_upload.yaml
  - override /logger: wandb.yaml # null  - wandb.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs
name: "triplet_id_net_fine_tuned"

seed: 12345

trainer:
  gpus: 1
  resume_from_checkpoint: null
  num_sanity_val_steps: 0
  min_epochs: 1
  max_epochs: 100
  gradient_clip_val: 0.5

model:
  vae_model_ckpt: /scratch/users/gsoykan20/projects/amazing-mysteries-of-gutter-demystified/logs/experiments/runs/vanilla_vae/2022-11-25_15-23-10/checkpoints/epoch_091.ckpt
  id_latent_dim: 128
  lr: 0.0005
  weight_decay: 0.01
  scheduler_gamma: 0.95

datamodule:
  data_dir: ${data_dir} # data_dir is specified in config.yaml
  folder_dir: ${data_dir}/icf_dass_faces
  batch_size: 512
  limit_search_files: null
  train_val_test_split: [ 0.92, 0.96, 1 ]
  num_workers: 5
  pin_memory: False

callbacks:
  early_stopping:
    patience: 5
    monitor: "val/loss" # name of the logged metric which determines when model is improving
    mode: "min" # "max" means higher metric value is better, can be also "min"

  # this is just for hparams search
  model_checkpoint:
    monitor: "val/loss" # name of the logged metric which determines when model is improving
    mode: "min" # "max" means higher metric value is better, can be also "min"
    save_top_k: 1
    save_last: True

logger:
  wandb:
    tags: [ "${name}", "id_embedding_extraction" ]
